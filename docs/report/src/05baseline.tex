\section{Baselines}
Our project investigates whether curriculum learning, a training paradigm inspired by the way humans learn progressively from simpler to more complex tasks, can enhance large language models' mathematical reasoning abilities.
To evaluate the effectiveness of our proposed approach, we selected Meta-Llama 3.1 8B (Base model, \underline{not} the Instruct model) \cite{touvron2023llamaopenefficientfoundation} as our primary baseline. We also considered the Mistral 7B model due to its strong performance and efficient architecture. However, we ultimately chose Meta-Llama 3.1 8B because of its more consistent results in multi-step reasoning benchmarks and broader support for instruction tuning, which aligned better with the goals of our project.

% Meta-Llama 3.1 8B is part of Metaâ€™s latest generation of instruction-tuned LLMs. It has been trained on a diverse and large-scale mixture of web documents, code, mathematics, natural language data, and synthetic data and has been instruction-tuned to handle a variety of downstream tasks, enabling it to perform various natural language tasks with relatively high fluency and reasoning ability. The 8B variant strikes a balance between computational feasibility and expressive power, making it well-suited for our experiments. We use it in a zero-shot and few-shot setting with and without chain-of-thought prompting to assess how well the model can perform complex reasoning tasks out of the box. 

The Meta-Llama 3.1 8B model has demonstrated strong performance across many benchmarks and benefits from its open weight release, making it ideal for reproducibility and customization in a research setting. We chose this model over alternatives for several reasons such as reasoning capability compared to efficiency, instruction tuning, open weights, and community support. Larger models like GPT-4 or Llama 3 70B offer higher accuracy but are computationally expensive and often impractical for iterative training paradigms like curriculum learning. Conversely, smaller models (e.g., 3B or 7B) offer efficiency but lack the reasoning depth needed to meaningfully test curriculum effects. Llama 3.1 8B strikes a practical balance, strong enough to exhibit reasoning growth, but efficient enough for staged training. Curriculum learning benefits from models that can follow fine-grained instructions and structured task sequences. % Llama 3.1 8B, being instruction-tuned, responds reliably to the varied prompting strategies required by our curriculum framework. Unlike many proprietary models, Llama 3.1 8B is openly available, allowing full access for controlled experiments, reproducibility, and potential fine-tuning, all of which are essential for our research.

While we also considered Mistral 7B, an open-weight model known for its inference efficiency and high performance on general NLP tasks, we ultimately did not select it as a baseline due to two reasons: (1) Llama 3.1 8B showed stronger performance in preliminary experiments on arithmetic reasoning tasks, and (2) its broader support for instruction-following made it a more natural fit for our use cases.
