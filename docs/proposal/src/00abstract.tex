\begin{abstract}
Mathematical reasoning remains a challenge for large language models (LLMs), requiring structured learning approaches to improve problem-solving capabilities. In this project, we explore curriculum learning as a strategy to enhance an LLMâ€™s mathematical proficiency by progressively fine-tuning it over multiple datasets. We first fine-tune the model on grade school mathematics before advancing to high school-level problems, leveraging techniques such as Chain of Thought (CoT) prompting, Self-Consistency (SC), and potentially a Mixture of Experts (MoE) approach. Our experimental design compares different finetuning strategies, including direct training on high school math versus a structured curriculum learning framework incorporating a pretrained teacher model. By systematically evaluating these methods, we aim to identify the most effective approach for improving mathematical reasoning in LLMs, with implications for broader applications in AI-driven education and automated advanced problem-solving.
\end{abstract}